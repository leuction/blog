---
title: 一些关于未来两年的VR/AR头显的乱七八糟的想法
description: 走向大众的第一个里程碑
date: "2022-02-23"
---

我第一次体验到VR，大概在Oculus Rift开始众筹，媒体纷纷开始吹VR元年之后不久。在成都的一次综合性的展会上。说实话，我对那次展会具体展出了什么东西没有什么印象，只记得在旁边的方便面的摊子上买了一份厂商用来宣传的汤达人，这碗方便面给我留下了比较深的印象，虽然之后很多年再吃一次感觉没有那么好吃了。在那场展会上，有人在那场展会上把Oculus Rift摆了出来，那年这么贵的新鲜玩意我肯定是要去试一试的。但是说实话，我对这玩意的印象不是太好，一个原因是他的画面模糊不堪，有严重的纱窗效应，第二个是他只有3个自由度，我只能在原地转转头，丝毫没有什么VR的感觉。

第二次是因为某个大佬买了PS VR，相比不知道从哪里冒出来的初创企业，索尼的名头可是大得多也响得多，开发能力也会更强。但是可惜的是，因为那时候人们对于晕动症还没有理解，一旦我想要移动，我就晕的想要吧昨天的饭吐出来。有了这么惨懂的记忆，我对VR的坏印象又上了一层楼。后面去Facebook的总部面试的时候，又尝试了一下，问题依旧。总的来说，我一直觉得它就是就是一个嫁接在现有的手机供应链上的产品，基本什么组件都是拿过来就用，组装一下而已。也难怪后来那么多打着VR旗号的骗子公司，比如著名的妖股暴风影音。

我一直觉得VR所设想的愿景远远没有到来，因为有着晕动症的惨痛教训，我对VR中的移动方式深感怀疑。说实话，第一个让我觉得眼前一亮的设计是Beat Saber，因为它很好的绕过了移动的问题。类似于智能手机刚出来的时候的一些手游的设计，比如利用陀螺仪模仿方向盘开车，利用多点触控的优势，用手指滑动，而不是现在大行其道的愚蠢的虚拟摇杆。Beat saber充分利用硬件的优势做出了只有这个设备形态才能完成的优秀的游戏设计。但是从另一个方面来说，这也只是权宜之计，如果VR想要发展，就一定要做出更有效的移动方式。之前看到不少人研发全向跑步机，我就一直坚信，只有全向跑步机普及，VR才能普及。

## 对AR的错判

当年，我更加看好AR，最大的原因当然是AR更容易解决晕动症的问题。因为可以看到周围的环境，虚拟物体叠加在真实物体之上，大脑前庭不会错乱，产生晕的感觉。当年看到Hololens出来之后，我非常确信它能够在3年左右变得可用。当然我错的很离谱，现在来看，我当时过于低估了光学设计的难度。我一直以为，SLAM是实现AR的最难的部分。事实上，随着AI的发展，SLAM的精度远远快于我的预估。另外，随着自动驾驶的需求发展和iPhone搭载激光雷达的影响，激光雷达的小型化和廉价化的速度远远超出任何人的想象，在短短几年间，激光雷达的价格从几十万迅速降低到几百。小型化的低端的激光雷达还会更便宜。随着手机行业的发展，AR在手机上的效果越来越好了。那么，剩下的问题就是，AR为什么依旧这么难以普及？

答案就是显示，相比于VR这种封闭的空间，AR的光路的设计难度高上一个级别。因为VR是封闭环境，遮蔽了环境光，所以一般来说，能达到100-200nit的亮度就已经足够。再者VR相对来说不强调便携。光路可以做到比较大，效率可以更高。而AR因为需要在开放环境中使用，亮度要求就要达到上千nit。要是能到户外的话，亮度可能要加一个数量级。而现有的几个互相竞争的光学设计中，自由曲面有更好的色彩，更大的FOV，但是体积过大，无法接受。在体积和显示效果的权衡下，大部分厂商都不约而同的选择了光波导，特别是衍射光波导。但是由于它的效率实在太低，本身光在传到过程中就要损失能量，又因为我们要进行扩瞳，总体来看，整个光路的效率只有1/5000。这时候，大部分显示设备就无法使用了，所以现在，Hololens和Magic leap使用过的光机只有Lcos和Mems快慢镜。但是我们也不是没有希望，未来可能能够成功的MicroLED能够有几百万nit的亮度，可能可以解决一部分问题，但是他也有生产成本以及均匀度的问题，现在有大量厂商在攻关巨量转移的问题了，相信在未来可以攻克。

问题不仅仅在于光机，因为红绿蓝三原色的频率不同，同一个光路很难对不同频率的光作出同样的行为。如果我们为每个颜色单独做一个通道，那么重量就变得不可接受。而且因为生产工艺的误差，三个镜片装配的不一致也会产生彩虹纹的问题。另外，本身这些镜片为了雕刻足够微小的光栅，需要及其困难的精密制造技术。人类现有的大规模精密制造技术只有光刻和纳米压印。这些要用来制造精密镜片难度还是很大。只能说，从现有的科技水平来看，AR还有很长时间要走。

## 迎来转折点的VR

相比于AR面临的重重困难，在显示层面，VR面临的困难就小得多。随着分辨率的提高和帧率的提高，晕动症的问题也得到缓解。原来要使用VR还需要连着一根线，现在越来越多的一体机，加上WiFi 6的普及。串流的效果也是差强人意。但是现在还有这一个问题，就是VR实在是太大太重了。分辨率可以说比几年前有着质的飞跃，但是也还是不够，模模糊糊看不太清楚。手柄追踪倒是因为AI的发展解决的不错，现在Oculus Quest通过手柄里面的惯性传感器加上视觉定位再加上AI插值。已经可以做到和传统由外向内的光学追踪差不多了，但是如果想要全身追踪，还是困难重重。

问题都在一个个得到解决，有一个现在可以确定的是，下一代VR头显，无论是苹果的，Facebook的还是Valve的都不约而同的选择了MicroOLED，传统显示面板的生产过程是将有机发光材料蒸镀到玻璃基板上，而MicroOLED是蒸镀到晶圆之上。他的缺点显而易见，这种制造方式和芯片制造流程几乎一样，虽然不用先进制程。芯片的成本和晶片的面积成正比，所以，大面积的MicroOLED就不太可能了。好处也是一样，因为晶圆的电路可以做的更小，所以像素密度可以做到更大。在头显领域常用的像素密度的衡量方式是ppd，iPhone 4的视网膜屏幕的ppd大约是60多，现有的一些头显的ppd大约在20左右。现在市面上为数不多低端MicroOLED的Arpara的ppd大概在30多，高端的Varjo能到70多。已经达到了人眼无法分辨的程度。

还有一个比较近的突破是Pancake折叠光学的量产，现在Pancake的供应链来自于3M。在这之前的光学设计基本都是菲涅耳透鏡。相比于原先的凸透镜，菲涅尔透镜已经非常小了。但是，现在一个头显的重量还是达到了1斤重，这个实在没有办法忍受。由于有了Pancake光路，光线在镜片之间不断的反射，从而起到减小光路的作用。如果以Arpara为例，这个头显的体积可以做到传统头显的一半左右。如果是研发能力更强的大厂，这个头显可能可以做到更小。

当然上面这两个技术也不是没有代价。更复杂的光路设计也意味着更高的能量损耗。现在一般的MicroOLED的颜色都是靠颜色透镜实现的，那么白光透过滤镜，大约70%左右的光都会被过滤掉。所以他的效率只有30%，再加上本身OLED调光都有占空比，标称亮度是基本无法实现的，这里，亮度要损止一个数量级。光线在透镜间反射，每次反射都会损失不少的光。所以这个光路的效率也只有10%。幸好我们人是在一个封闭的环境中，只要200nit左右的亮度就很高了。总的来说，MicroOLED需要的亮度有几万到几十万的量级，能生产这样的屏幕难度很大，但不是不能实现。

另外一个非常重要的技术是眼部追踪，我们知道，假设下一代头显的每支眼的标准分辨率是4k * 4k的话，那么总共的渲染分辨率可以类比为8k。这么搞的分辨率任何显卡都是很难吃的消的。如果我们记得DX12发布的时候有一个特性就是VRS，可变速率渲染。如果我们把眼球追踪和VRS结合，那么我们就可以把算力集中在眼睛注视的地方。人的视野极限能有将近200度，但是实际能看清的也只有40度左右。这样可以极大的节省算力。当然，有了眼球追踪，加上嘴部追踪的话，我们就可以重建表情了，这个对于VRChat一类的应用是帮助非常大的。

从供应链来看，苹果也没有办法解决光波导的难题，所以选择了通过VR加上see through的方式来解决。这种方法有一定的问题，我们是通过摄像头来看到外界，有一定的危险性，一个延迟就会：轻则是我们头晕目眩，重则造成危险。而且，由于是摄像头的重建画面，我们是很容易失去对外界的距离感知，结果就是虚拟的物品效果比真实物体的效果好。但是这些都是可以弥补的。这种AR很难带出门，只能用在特殊情况下。但是相比较光波导那一大堆彩虹纹和小到无法理解的FOV，这种方案至少能给客户一个特定情况下能用的解决方案了。